---
title: Redis知识归纳(三)高可用、高并发
date: 2020-04-02 22:49:40
tags: Redis
categories: Redis
---

在Redis分布式锁那篇 文章，我们提到过Redis的高可用如何实现。这篇文章，我们就系统来讲解一下Redis主从架构、哨兵模式以及集群模式。

<!-- more -->

### 主从架构

单机Redis能够承载的QPS大概上万到几万不等。因此架构做成主从架构，一主多从，主负责写，并且将数据复制到其他从节点上，从节点负责读。所有读请求全部走从节点，这样的架构很容易水平扩容，从而实现**读高并发**。

![](redis4/redis-master-slave.png)

#### 主从复制的核心原理

当启动一个从节点时，它会发送一个**PSYNC**命令给主节点。

如果这是从节点第一次连接到主节点上，那么就会触发一次**全量复制**。此时主节点会启动一个后台程序，开始在磁盘生成一份RDB快照，同时，还会将接收到的新的写命令缓存在内存中。RDB文件生成完毕后，mater会把这个RDB发送给slave。**slave会先写入本地磁盘，然后从本地磁盘中加载到内存中**，接着maser会将内存中的缓存写命令发送给slave，slave也会同步这些数据。slave如果跟master断开了连接，会自动重连，连接之后master会复制给slave缺少的部分。

那么**断点续传**的原理是什么？

主节点会在内存中维护一个backlog，主节点和从节点都会保存一个offset，还有一个master run id。如果主节点和从节点断开连接，下次重连后，从节点会让主节点从offset的地方开始继续复制，如果没有找到offset，那么就重新来一次全量复制。

或者可以配置成 **无磁盘化复制**。

主节点直接在内存中创建RDB，发送给从节点 。

#### 过期key处理

从节点不会处理过期key，只会等待主节点来淘汰自己的过期key。当主节点删除一个过期key后，会模拟一条del命令发送给从节点。

### 哨兵模式

##### 哨兵的功能

1. 集群监控：负责监控redis master和slave进程是否正常工作
2. 消息通知：如果某个redis 实例有故障，那么哨兵负责发送警报给管理员
3. 故障转移：如果master挂掉，那么会自动转移到slave 节点上。
4. 配置中心：如果发生故障转移，那么会通知客户端新的master地址。

哨兵用于实现redis集群的**高可用**。

##### 哨兵的要求

哨兵模式要求**两个以上**节点，即最少三个实例，来保障程序的健壮性。

经典的 3 节点哨兵集群是这样的：

```java
       +----+
       | M1 |
       | S1 |
       +----+
          |
+----+    |    +----+
| R2 |----+----| R3 |
| S2 |         | S3 |
+----+         +----+
```

##### 哨兵主备切换的数据丢失问题

1. 异步复制导致的数据丢失

因为master到slave的复制是异步的，有可能master还有数据没有达到slave，此时master宕机，那么这部分数据就会丢失。

2. 脑裂导致数据丢失

**脑裂**是指，当master所在机器跟其他节点脱离了正常的网络，跟其他slave机器不能连接，但实际上还是运行的。此时哨兵可能认为master宕机了，然后开始选举，将其他slave切换为master。此时集群里面就有两个matser，也就是所谓的**脑裂**。

但此时客户端可能还没来得及切换到新的master，仍然往旧的mater上写数据。旧的master会重新作为slave挂在新的master上，自己的数据会清空，从新的mater上复制数据。因此，新的master没有后来客户端写的数据，因此这部分数据就发生了丢失。

##### 数据丢失的解决方案

```java
min-slaves-to-write 1
min-slaves-max-lag 10
```

要求至少有1个slave连接到master上，数据复制和同步的延迟不能超过10秒。否则master就拒接写请求，这样如果发生脑裂，原先的master节点接受客户端的写入请求会被拒绝，就可以减少数据丢失问题。

##### 哨兵集群的自动发现机制

哨兵之间相互发现是通过Redis的pub/sub 发布/订阅系统实现的。

每个哨兵都会往 **sentinel:hello**这个channel上发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感其他哨兵的存在。

每隔两秒中，每个哨兵都往自己监控的某个 master+slaves对应的**sentinel:hello** channel里面发送一个消息，内容是自己的host ip 和 runid 还有对这个master的监控配置

每个哨兵也会监听自己监控的master + slaves对应的**sentinel:hello**的channel，然后去感知同样在监听这个master + slaves的其他哨兵的存在。

每个哨兵还会跟其他哨兵交换对master的监控配置，互相进行监控配置的同步。

##### 哨兵主从选举算法

某个哨兵发现某个实例回复ping命令超过指定的值，那么就被标记为**主观下线**，如果主节点被标记为主观下线，那么所有哨兵都会每秒一次的频率来确认主节点的确进入了主观下线。

当足够数量的哨兵都同意这一判断，那么主节点被会认为**客观下线**。如果大多数的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作。此时会首先选举出一个slave来，使其变为主服务器。然后通过发布和订阅功能，将更新后的配置发送给其他哨兵，其他哨兵把自己的配置进行更新。同时通知其他slave，让他们去复制新的主服务器。当所有从服务器都开始复制新的主服务器，那么执行主备切换的哨兵就完成此次故障迁移操作。

### Redis集群

在早年间，redis如果想要多实例，每个实例存储一部分数据，需要一些中间件来实现，比如 codis、twemproxy。原理是通过读写中间件，中间件将数据分布式存储在多台机器的实例上。

现在redis原生支持redis集群模式，主要针对的是海量数据+高并发+高可用场景。redis cluster支撑N个redis master node，每个master node都可以挂载多个slave node。这样整个redis就可以横向扩容。

##### 分布式寻址算法

hash算法
一致性hash算法 + 虚拟节点
redis cluster的hash slot算法

1. hash算法

对key计算哈希值后对节点数去模。但是这个做法的最大问题是一旦某个节点宕机，所有节点请求过来后会基于最新的剩余master节点数取模，尝试去取数据。这会导致大部分的请求过来，全部无法拿到有效的缓存，从而导致大量的流量涌入数据库，造成缓存雪崩。

2. 一致性hash算法

一致性hash算法是将整个hash值空间组织成一个虚拟的环，整个空间按照顺时针反向组织，下一步将各个master节点（使用服务器的ip 或者 主机名）进行hash。这样就能确定每个节点在其hash环上的位置。

对key计算哈希值，确定此数据在圆环上的位置，从此位置沿圆环顺时针行走，遇到第一个master节点就是key所在的位置。

在一致性hash算法中，如果一个节点挂了，那么受影响的数据仅仅是此节点到环空间前一个节点之间的数据，其他的不会会受到影响。但是如果当节点太少时，容易因为节点分布不均匀造成缓存热点倾斜的问题。为了解决这个问题，一致性hash算法引入了虚拟节点的机制，即对每一个节点计算多个hash，每个计算结果的位置都放置一个服务节点，称虚拟节点，具体做法可以在服务器ip或者主机名后面增加编号来实现。例如可以为每台服务器计算三个虚拟节点，于是可以分别计算“Node A#1”、“Node A#2”、“Node A#3”，数据定位算法不变，只是多一步虚拟节点到实际节点的映射。因此通过虚拟节点可以做到相对均匀的数据分布。

![](redis4/consistent-hashing-algorithm.png)

3. redis cluster 的 hash slot算法

redis cluster有固定的16384个hash slot。对每个 key 计算 CRC16值，然后对16384取模，可以获取key对应的hash slot。redis cluster 中的每个master都会持有部分slot，比如有3个master,那么每个master都持有5000多个哈希槽。哈希槽让node的增加和移除都很简单，增加一个master，就将其他master的slot 移动部分过去，减少一个master，就将其slot移动到其他master上。

##### redis cluster的高可用与主备切换原理

redis cluster的高可用，几乎跟哨兵类似。

1. 判断节点宕机

如果一个节点认为另外一个节点宕机，那么就是pfail ,主观宕机，当多数节点认为另外一个节点宕机了，那么就是fail，客观宕机。当在指定时间内没有回复pong，则被认为是pfail。如果一个节点认为某个节点pfail，那么就会告诉其他节点，如果超过半数的节点认为pfail，那么就是fail。

2. 从节点过滤

对宕机的master node，从其所有的slave node中选择一个切换为master node。检查每个slave 与 master 断开连接的时间，如果超过了指定时间，就没有资格成为master。

3. 从节点选举

每个从节点都根据自己对master复制数据的offset，来设置一个选举时间，offset越大，意味着从主节点复核的数据越多，那么选举时间越靠前，优先进行选举。

所有master开始slave选举，给要进行选举的slave进行投票，如果大部分的master（N/2+1）都投票给了某个从节点，那么选举通过，那个从节点变为master。从节点执行主备切换，从节点切换为主节点。

所以redis cluster就是一个 replication 和 sentinel 的结合体。
